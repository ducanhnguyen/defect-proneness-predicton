# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
show(precision)
list(tp, tn, fp, fn, precision, accuracy, recall, Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, jdt, jdt, jdt$buggy, 0.5)
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
model = rpart(formula, data=jdt, method='class')
predictedOutput = predict(model, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
show(precision)
list("tp"=tp, tn, fp, fn, precision, accuracy, recall, Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, jdt, jdt, jdt$buggy, 0.5)
tree$tp
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
model = rpart(formula, data=jdt, method='class')
predictedOutput = predict(model, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
show(precision)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, jdt, jdt, jdt$buggy, 0.5)
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
model = rpart(formula, data=jdt, method='class')
predictedOutput = predict(model, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, jdt, jdt, jdt$buggy, 0.5)
tree$precision
tree$recall
tree$Fscore
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
tree = rpart(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, data=jdt, method='class')
plot(tree)
text(tree)
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, jdt, jdt, jdt$buggy, 0.5)
tree$precision
tree$accuracy
tree$recall
tree$Fscore
tree$tp
tree$tn
tree$fp
tree$fn
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
tree = rpart(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope+bf+noc+loc, data=jdt, method='class')
plot(tree)
text(tree)
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, jdt, jdt, jdt$buggy, 0.5)
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope+bf+loc+noc, jdt, jdt, jdt$buggy, 0.5)
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope+bf+loc+noc, jdt, jdt, jdt$buggy, 0.5)
tree$tp
tree$tn
tree$fp
tree$fn
tree$precision
tree$accuracy
tree$recall
tree$Fscore
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, jdt, jdt, jdt$buggy, 0.5)
tree$tp
tree$tn
tree$fp
tree$fn
tree$precision
tree$accuracy
tree$recall
tree$Fscore
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope+bf+loc+noc, jdt, jdt, jdt$buggy, 0.5)
tree$tp
tree$tn
tree$fp
tree$fn
tree$precision
tree$accuracy
tree$recall
tree$Fscore
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope, jdt, jdt, jdt$buggy, 0.5)
tree$tp
tree$tn
tree$fp
tree$fn
tree$precision
tree$accuracy
tree$recall
tree$Fscore
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~type+refer+pattern+bind+code+locat+declar+method+java+complet+parser+compil+field+match+packag+intern+name+snippet+search+scope+bf+loc+noc, jdt, jdt, jdt$buggy, 0.5)
tree$tp
tree$tn
tree$fp
tree$fn
tree$precision
tree$accuracy
tree$recall
tree$Fscore
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~bf+loc+noc, jdt, jdt, jdt$buggy, 0.5)
tree$tp
tree$tn
tree$fp
tree$fn
tree$precision
tree$accuracy
tree$recall
tree$Fscore
# Select high recall term roots >= 0.03
library(rpart)
setwd("C:\\Users\\adn0019\\WORK\\workspace\\eclipse\\defect-proneness-predicton\\data")
jdt = read.csv('jdt_high_recall_termroots.csv', header=TRUE, sep =",")
jdt$buggy = ifelse(jdt$bug==0,0,1)
decision_tree_model = function(formula, training, testing, actual, threshold){
# STEP 1
tree = rpart(formula, data=jdt, method='class')
plot(tree)
text(tree)
show(tree)
predictedOutput = predict(tree, data=testing, type = 'prob')
# Step 2
tp = tn = fp = fn = 0
for (i in 1:length(actual)){
if (actual[i]==1){
if (predictedOutput[i] >= threshold) # POSITIVE
tp = tp + 1
else				# NEGATIVE
fn = fn + 1
}else{
if (predictedOutput[i] >= threshold)	# POSITIVE
fp = fp + 1
else				# NEGATIVE
tn = tn + 1
}
}
# Step 3
precision = tp / (tp + fp)
accuracy = (tp + tn) / length(predictedOutput)
recall = tp / (tp + fn)
Fscore = 2/(1/precision + 1/recall)
list("tp"=tp, "tn" = tn, "fp" = fp, "fn" = fn, "precision" = precision, "accuracy" = accuracy, "recall" = recall, "Fscore" = Fscore)
}
tree = decision_tree_model(buggy~bf+loc+noc, jdt, jdt, jdt$buggy, 0.5)
tree$tp
tree$tn
tree$fp
tree$fn
tree$precision
tree$accuracy
tree$recall
tree$Fscore
